{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#from dfply import arrange\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"/home/rsrg9/Documents/tunc_oz/apply_model\"\n",
    "#path1 = \"D:/tunc_oz/apply_model\"\n",
    "os.chdir(path1)\n",
    "\n",
    "# Second path\n",
    "path2 = \"csv_data_r_import/cologne/scale\"\n",
    "os.chdir(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_fit(x, y, index_train=None):\n",
    "    # Expand coarse grid\n",
    "    coarse_grid = {'C': 2.0 ** np.arange(-4, 13, 2),\n",
    "                   'gamma': 2.0 ** np.arange(-5, 4, 2)}\n",
    "    \n",
    "    kappa_scorer = make_scorer(cohen_kappa_score)\n",
    "\n",
    "    # Coarse grid search\n",
    "    svm_coarse = SVC(kernel='rbf')\n",
    "    svm_coarse_cv = GridSearchCV(svm_coarse, param_grid=coarse_grid, scoring=kappa_scorer)#, cv=index_train)\n",
    "    svm_coarse_cv.fit(x, y)\n",
    "    \n",
    "    # Get best coarse grid parameters\n",
    "    best_c = svm_coarse_cv.best_params_['C']\n",
    "    best_gamma = svm_coarse_cv.best_params_['gamma']\n",
    "    \n",
    "    # Define narrow grid borders\n",
    "    a_gamma = np.log2(best_gamma) - 2\n",
    "    b_gamma = np.log2(best_gamma) + 2\n",
    "    a_c = np.log2(best_c) - 2\n",
    "    b_c = np.log2(best_c) + 2\n",
    "    \n",
    "    # Expand narrow grid\n",
    "    narrow_grid = {'C': 2.0 ** np.arange(a_c, b_c, 0.5),\n",
    "                   'gamma': 2.0 ** np.arange(a_gamma, b_gamma, 0.5)}\n",
    "    \n",
    "    # Narrow grid search\n",
    "    svm_narrow = SVC(kernel='rbf')\n",
    "    svm_narrow_cv = GridSearchCV(svm_narrow, param_grid=narrow_grid, scoring=kappa_scorer)#, cv=index_train)\n",
    "    svm_narrow_cv.fit(x, y)\n",
    "    \n",
    "    return svm_narrow_cv\n",
    "\n",
    "# Usage example:\n",
    "# svm_model = svm_fit(X_train, y_train, StratifiedKFold(n_splits=10, shuffle=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean Distance between two points lying in the input space\n",
    "def euc_dis(a, b):\n",
    "    temp = 0\n",
    "    for ii in range(len(a)):\n",
    "        temp += (a[ii] - b[ii])**2\n",
    "    return np.sqrt(temp)\n",
    "\n",
    "# Evaluate the distance between Virtual Support Vectors and Support Vectors lying in the input space\n",
    "def rem_extrem(org, VSV1, a):\n",
    "    distance = pd.DataFrame(index=range(len(org)), columns=['label', 'distance'])\n",
    "    distanceSVC1 = []\n",
    "    distanceSVC2 = []\n",
    "    \n",
    "    for l in range(len(org)):\n",
    "        distance.loc[l, 'label'] = str(org.iloc[l, -1])\n",
    "        distance.loc[l, 'distance'] = euc_dis(org.iloc[l, :-1], VSV1.iloc[l, :-1])\n",
    "    \n",
    "    SVClass1 = org[org['REF'] == org['REF'].unique()[0]]\n",
    "    SVClass2 = org[org['REF'] == org['REF'].unique()[1]]\n",
    "    \n",
    "    if len(SVClass1) > 0:\n",
    "        for n in range(len(SVClass1) - 1):\n",
    "            for nn in range(n, len(SVClass1) - 1):\n",
    "                distanceSVC1.append(euc_dis(SVClass1.iloc[n, :-1], SVClass1.iloc[n + nn, :-1]))\n",
    "        disClass1median = np.mean(distanceSVC1)\n",
    "        boundClass1 = disClass1median * a\n",
    "    \n",
    "    if len(SVClass2) > 0:\n",
    "        for n in range(len(SVClass2) - 1):\n",
    "            for nn in range(n, len(SVClass2) - 1):\n",
    "                distanceSVC2.append(euc_dis(SVClass2.iloc[n, :-1], SVClass2.iloc[n + nn, :-1]))\n",
    "        disClass2median = np.mean(distanceSVC2)\n",
    "        boundClass2 = disClass2median * a\n",
    "    \n",
    "    for k in range(len(org)):\n",
    "        if np.isnan(distance.loc[k, 'distance']):\n",
    "            VSV1.iloc[k, :] = np.nan\n",
    "        else:\n",
    "            if boundClass1 is not None:\n",
    "                if distance.loc[k, 'label'] == org['REF'].unique()[0]:\n",
    "                    if distance.loc[k, 'distance'] > boundClass1:\n",
    "                        VSV1.iloc[k, :] = np.nan\n",
    "            else:\n",
    "                if boundClass2 is not None:\n",
    "                    if distance.loc[k, 'label'] == org['REF'].unique()[1]:\n",
    "                        if distance.loc[k, 'distance'] > boundClass2:\n",
    "                            VSV1.iloc[k, :] = np.nan\n",
    "    return VSV1\n",
    "\n",
    "# Kernel distance between two points lying in the hyperspace\n",
    "def kern_dis(a, b, kernelfunc):\n",
    "    a = np.array(a).flatten()\n",
    "    b = np.array(b).flatten()\n",
    "    dk = np.sqrt(kernelfunc(a, a) + kernelfunc(b, b) - 2 * kernelfunc(a, b))\n",
    "    return dk\n",
    "\n",
    "# Evaluate the distance between Virtual Support Vectors and Support Vectors lying in the hyperspace\n",
    "def rem_extrem_kerneldist(org, VSV1, a, kernelfunc):\n",
    "    distance = pd.DataFrame(index=range(len(org)), columns=['label', 'distance'])\n",
    "    distanceSVC1 = []\n",
    "    distanceSVC2 = []\n",
    "    \n",
    "    for l in range(len(org)):\n",
    "        distance.loc[l, 'label'] = str(org.iloc[l, -1])\n",
    "        distance.loc[l, 'distance'] = kern_dis(org.iloc[l, :-1], VSV1.iloc[l, :-1], kernelfunc)\n",
    "    \n",
    "    SVClass1 = org[org['REF'] == org['REF'].unique()[0]]\n",
    "    SVClass2 = org[org['REF'] == org['REF'].unique()[1]]\n",
    "    \n",
    "    if len(SVClass1) > 0:\n",
    "        for n in range(len(SVClass1) - 1):\n",
    "            for nn in range(n, len(SVClass1) - 1):\n",
    "                distanceSVC1.append(kern_dis(SVClass1.iloc[n, :-1], SVClass1.iloc[n + nn, :-1], kernelfunc))\n",
    "        disClass1median = np.mean(distanceSVC1)\n",
    "        boundClass1 = disClass1median * a\n",
    "    \n",
    "    if len(SVClass2) > 0:\n",
    "        for n in range(len(SVClass2) - 1):\n",
    "            for nn in range(n, len(SVClass2) - 1):\n",
    "                distanceSVC2.append(kern_dis(SVClass2.iloc[n, :-1], SVClass2.iloc[n + nn, :-1], kernelfunc))\n",
    "        disClass2median = np.mean(distanceSVC2)\n",
    "        boundClass2 = disClass2median * a\n",
    "    \n",
    "    for k in range(len(org)):\n",
    "        if np.isnan(distance.loc[k, 'distance']):\n",
    "            VSV1.iloc[k, :] = np.nan\n",
    "        else:\n",
    "            if boundClass1 is not None:\n",
    "                if distance.loc[k, 'label'] == org['REF'].unique()[0]:\n",
    "                    if distance.loc[k, 'distance'] > boundClass1:\n",
    "                        VSV1.iloc[k, :] = np.nan\n",
    "            else:\n",
    "                if boundClass2 is not None:\n",
    "                    if distance.loc[k, 'label'] == org['REF'].unique()[1]:\n",
    "                        if distance.loc[k, 'distance'] > boundClass2:\n",
    "                            VSV1.iloc[k, :] = np.nan\n",
    "    return VSV1\n",
    "\n",
    "def pred_one(model, data_point):\n",
    "    # Extract necessary components from the SVM model\n",
    "    support_vectors = model.n_support_\n",
    "    kernel_function = model.kernel\n",
    "    coefficients = model.dual_coef_.ravel()\n",
    "    intercept = model.intercept_\n",
    "    \n",
    "    # Initialize prediction variable\n",
    "    prediction = 0\n",
    "    \n",
    "    # Iterate over each support vector\n",
    "    for j in range(len(support_vectors)):\n",
    "        # Compute kernel function value between the j-th support vector and the data point\n",
    "        kernel_value = kernel_function(data_point.reshape(1, -1), model.support_vectors_[j, :].reshape(1, -1))\n",
    "        \n",
    "        # Multiply kernel value by the corresponding coefficient and add to prediction\n",
    "        weighted_value = kernel_value * coefficients[j]\n",
    "        prediction += weighted_value\n",
    "    \n",
    "    # Subtract intercept to get the final prediction\n",
    "    final_prediction = prediction - intercept\n",
    "    \n",
    "    return final_prediction\n",
    "\n",
    "def uncertainty_dist_v2_2(org, samp):\n",
    "    distance = pd.DataFrame(columns=['control_label', 'distance'], index=range(len(samp)))\n",
    "    \n",
    "    for k in range(len(samp)):\n",
    "        distance.loc[k, 'distance'] = np.sign(pred_one(org.finalModel, samp.iloc[k, :-1])) * \\\n",
    "                                      np.where(pred_one(org.finalModel, samp.iloc[k, :-1]) > 0, 1, -1)\n",
    "    \n",
    "    # Normalize distance\n",
    "    preProc = preprocessing.MinMaxScaler()\n",
    "    preProc.fit(distance[['distance']])\n",
    "    normdistance = preProc.transform(distance[['distance']])\n",
    "    \n",
    "    samp['normdistance'] = normdistance\n",
    "    \n",
    "    return samp\n",
    "\n",
    "def alter_labels(distance_data, ref):\n",
    "    # Merge features and original labels\n",
    "    ref_added = pd.concat([distance_data, ref], axis=1)\n",
    "    # Order by most uncertain samples\n",
    "    ref_added_or = ref_added.sort_values(by='distance')\n",
    "    # Re-label most uncertain n number of samples\n",
    "    ref_added_or.iloc[:250, -1] = ref_added_or.iloc[:250, -2]\n",
    "    ref_added_or.iloc[:250, -2] = 1.0\n",
    "    # Re-order dataset by its index\n",
    "    ref_added_or['index'] = range(len(ref_added_or))\n",
    "    ref_added_reor = ref_added_or.sort_values(by='index')\n",
    "    \n",
    "    # Extract labels for prediction\n",
    "    labels = ref_added_reor.iloc[:, -5]\n",
    "    return labels\n",
    "\n",
    "def ExCsvMSD(datadase, filename=None):\n",
    "    # Convert to numpy array\n",
    "    datadase = np.array(datadase)\n",
    "    n = datadase.shape[1]\n",
    "    MSDdata = np.empty((2, n), dtype=float)\n",
    "    \n",
    "    MSDdata[0, :] = np.mean(datadase, axis=0)\n",
    "    MSDdata[1, :] = np.std(datadase, axis=0)\n",
    "    \n",
    "    MSDdata_final = np.vstack((datadase, MSDdata))\n",
    "    \n",
    "    # Export final mean and standard deviation to .csv-file\n",
    "    if filename is not None:\n",
    "        pd.DataFrame(MSDdata_final).to_csv(filename, index=False, header=False)\n",
    "    \n",
    "    return MSDdata_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputPath = \"cologne_res_100_L2-L13.csv\"\n",
    "sMax = 1000\n",
    "bound = [0.3, 0.6, 0.9]\n",
    "boundMargin = [1.5, 1.0, 0.5]\n",
    "sampleSizesPor = [40, 25, 16, 12, 10, 8, 6, 4, 3, 2, 1]\n",
    "colheader = [\"40\", \"25\", \"16\", \"12\", \"10\", \"8\", \"6\", \"4\", \"3\", \"2\", \"1\"]\n",
    "sindexSVMDATA = 36\n",
    "numFeat = 18\n",
    "eindexSVMDATA = sindexSVMDATA + numFeat - 1\n",
    "objInfoNames = [\"Lx_g_comp\", \"Lx_g_elfi\", \"Lx_g_refi\", \"Lx_g_roun\", \"Lx_g_shin\",\n",
    "                \"Lx_m_bl\", \"Lx_m_gr\", \"Lx_m_ndvi\", \"Lx_m_nir\", \"Lx_m_re\",\n",
    "                \"Lx_sd_bl\", \"Lx_sd_gr\", \"Lx_sd_ndvi\", \"Lx_sd_nir\", \"Lx_sd_re\",\n",
    "                \"Lx_t_diss\", \"Lx_t_hom\", \"Lx_t_mean\",\n",
    "                \"label\"]\n",
    "columnClass = [None] * 217 + [\"factor\", \"integer\"]\n",
    "\n",
    "# Import data\n",
    "preproc_DataPool = pd.read_csv(inputPath, header=0, sep=\";\", dtype=str, na_values=None)\n",
    "\n",
    "tmp_DataPool = preproc_DataPool.iloc[:, :-2]\n",
    "\n",
    "generalDataPool_columns = tmp_DataPool.columns\n",
    "\n",
    "converters = {col: lambda x: float(x.replace(',', '.')) for col in generalDataPool_columns}\n",
    "generalDataPool = pd.read_csv(inputPath, header=0, sep=\";\", na_values=None, converters=converters)\n",
    "\n",
    "\n",
    "generalDataPool.dropna(subset=[\"REF\"], inplace=True)  # Remove rows with missing REF values\n",
    "generalDataPool[\"REF\"] = pd.Categorical(generalDataPool[\"REF\"])\n",
    "\n",
    "# Transform to 2-Class-Case \"Bushes Trees\" VS rest\n",
    "first_label_class = generalDataPool[\"REF\"].cat.categories[0]  # Note that the first record is of class \"bushes trees\"\n",
    "generalDataPool[\"REF\"] = generalDataPool[\"REF\"].apply(lambda x: first_label_class if x == first_label_class else \"other\")\n",
    "generalDataPool[\"REF\"] = pd.Categorical(generalDataPool[\"REF\"])\n",
    "\n",
    "data = generalDataPool.iloc[:, sindexSVMDATA:eindexSVMDATA + 1]\n",
    "REF = generalDataPool.iloc[:, -1]\n",
    "data_with_label = pd.concat([data, REF], axis=1)\n",
    "data_label = data_with_label.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generalDataPool.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizedFeat['L02_G_COMP'] = normalizedFeat['L02_G_COMP'].replace(',', '.', regex=True)\n",
    "#normalizedFeat['L02_G_COMP'] = normalizedFeat['L02_G_COMP'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizedFeat['L02_G_EFIT'] = normalizedFeat['L02_G_EFIT'].apply(lambda x: pd.to_numeric(x.str.replace(',', '.'), errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizedFeat = generalDataPool.iloc[:, :-2]\n",
    "normalizedLabelUSE = generalDataPool.iloc[:, -2:]\n",
    "\n",
    "# Scaling\n",
    "preProc = MinMaxScaler()\n",
    "normalizedFeatBase = pd.DataFrame(preProc.fit_transform(normalizedFeat.iloc[:, sindexSVMDATA:eindexSVMDATA + 1]), columns=objInfoNames[:-1])\n",
    "\n",
    "# Apply range of basemodel to all levels\n",
    "normalizedFeat2 = pd.DataFrame(preProc.fit_transform(normalizedFeat.iloc[:, :numFeat]), columns=objInfoNames[:-1])\n",
    "normalizedFeat3 = pd.DataFrame(preProc.fit_transform(normalizedFeat.iloc[:, numFeat:(2 * numFeat)]), columns=objInfoNames[:-1])\n",
    "normalizedFeat5 = pd.DataFrame(preProc.fit_transform(normalizedFeat.iloc[:, (3 * numFeat):(4 * numFeat)]), columns=objInfoNames[:-1])\n",
    "normalizedFeat6 = pd.DataFrame(preProc.fit_transform(normalizedFeat.iloc[:, (4 * numFeat):(5 * numFeat)]), columns=objInfoNames[:-1])\n",
    "normalizedFeat7 = pd.DataFrame(preProc.fit_transform(normalizedFeat.iloc[:, (5 * numFeat):(6 * numFeat)]), columns=objInfoNames[:-1])\n",
    "normalizedFeat8 = pd.DataFrame(preProc.fit_transform(normalizedFeat.iloc[:, (6 * numFeat):(7 * numFeat)]), columns=objInfoNames[:-1])\n",
    "normalizedFeat9 = pd.DataFrame(preProc.fit_transform(normalizedFeat.iloc[:, (7 * numFeat):(8 * numFeat)]), columns=objInfoNames[:-1])\n",
    "normalizedFeat10 = pd.DataFrame(preProc.fit_transform(normalizedFeat.iloc[:, (8 * numFeat):(9 * numFeat)]), columns=objInfoNames[:-1])\n",
    "normalizedFeat11 = pd.DataFrame(preProc.fit_transform(normalizedFeat.iloc[:, (9 * numFeat):(10 * numFeat)]), columns=objInfoNames[:-1])\n",
    "\n",
    "# Recombine normalized sets to one data frame\n",
    "normalizedDataPoolAllLev = pd.concat([normalizedFeat2, normalizedFeat3, normalizedFeatBase, normalizedFeat5,\n",
    "                                      normalizedFeat6, normalizedFeat7, normalizedFeat8, normalizedFeat9,\n",
    "                                      normalizedFeat10, normalizedFeat11, normalizedLabelUSE], axis=1)\n",
    "\n",
    "# Remove used temporary variables\n",
    "del normalizedFeat, normalizedFeat2, normalizedFeat3, normalizedFeatBase, normalizedFeat5, normalizedFeat6\n",
    "del normalizedFeat7, normalizedFeat8, normalizedFeat9, normalizedFeat10, normalizedFeat11\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into test, train, and validate data\n",
    "trainDataPoolAllLev, testDataAllLev, validateDataAllLev = [df for _, df in normalizedDataPoolAllLev.groupby('USE')]\n",
    "trainDataPoolAllLev = trainDataPoolAllLev.iloc[:, :-1]\n",
    "testDataAllLev = testDataAllLev.iloc[:, :-1]\n",
    "validateFeatAllLev = validateDataAllLev.iloc[:, :-2]\n",
    "validateLabels = validateDataAllLev.iloc[:, -2]\n",
    "\n",
    "# Order train data pool by class label in alphabetical order\n",
    "trainDataPoolAllLev = trainDataPoolAllLev.sort_values(by=trainDataPoolAllLev.columns[-1])\n",
    "\n",
    "# Current training data-set, updated (refreshed) after each iteration\n",
    "trainDataCur = trainDataPoolAllLev.copy()\n",
    "testDataCur = testDataAllLev.copy()\n",
    "\n",
    "# Set randomized seed for the random sampling procedure\n",
    "seed = 5\n",
    "\n",
    "# Initial seed value for randomized sampling\n",
    "seed += np.random.randint(1, 101)\n",
    "\n",
    "# Definition of apriori-probabilities\n",
    "pA = pB = pC = pD = pE = pF = 1 / 6\n",
    "\n",
    "# Definition of training sample set sizes S [% of max. sample size]\n",
    "sCur = sMax * (sampleSizesPor[0] / 100)\n",
    "# Definition of sample shares\n",
    "nA, nB, nC, nD, nE, nF = [round(sCur * p) for p in [pA, pB, pC, pD, pE, pF]]\n",
    "shares = np.array([nA, nB, nC, nD, nE, nF])\n",
    "\n",
    "# Set randomized seed for the random sampling procedure\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'REF'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validateDataAllLev.columns[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratSamp = trainDataCur.groupby('REF', observed=False)[trainDataCur.columns].apply(lambda x: x.sample(67, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sampling function\n",
    "def sample_within_group(group):\n",
    "    # Add the original IDs as a new column\n",
    "    group['ID_unit'] = group.index\n",
    "    \n",
    "    # Perform sampling within the group\n",
    "    sampled_group = group.sample(min(len(group), 67), replace=False)\n",
    "    \n",
    "    return sampled_group\n",
    "\n",
    "# Apply the sampling function to each group\n",
    "stratSamp = trainDataCur.groupby('REF', observed=False).apply(sample_within_group)\n",
    "\n",
    "# Reset the index to obtain a flat DataFrame with the original IDs preserved\n",
    "stratSamp.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Get samples of trainDataCur and set trainDataCur new\n",
    "trainDataCurRemaining = trainDataCur.drop(stratSamp[\"ID_unit\"])\n",
    "\n",
    "# Split test feat from test label for later join with trainData\n",
    "trainFeat = stratSamp.iloc[:, :len(trainDataPoolAllLev.columns)-1]\n",
    "trainLabels = stratSamp.iloc[:, len(trainDataPoolAllLev.columns)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainDataPoolAllLev.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'REF'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stratSamp.columns[len(trainDataPoolAllLev.columns)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratSamp = trainDataCur.groupby('REF',observed=False)\n",
    "#stratSamp = stratSamp.apply(lambda x: x.sample(67, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of sampling configuration (strata: random sampling without replacement)\n",
    "#stratSamp = trainDataCur.groupby('REF').apply(lambda x: x.sample(shares, replace=False)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lx_t_diss'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataCur.columns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratSamp.iloc[:,181]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratSamp[\"ID_unit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeat.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Subset for each outer iteration test data to speed up computing\n",
    "testDataCur = testDataCur.sort_values(by=testDataCur.columns[-1])\n",
    "# Apply the sampling function to each group\n",
    "stratSamp = testDataCur.groupby('REF', observed=False).apply(sample_within_group)\n",
    "\n",
    "# Split test feat from test label for later join with trainData\n",
    "testFeat = stratSamp.iloc[:, :len(testDataCur.columns)-1]\n",
    "testLabels = stratSamp.iloc[:, len(testDataCur.columns)-1]\n",
    "\n",
    "# Subset on base level\n",
    "testFeatsub = testFeat.iloc[:, sindexSVMDATA:eindexSVMDATA + 1]\n",
    "\n",
    "# TrainData index to split between train and test in svmFit\n",
    "countTrainData = trainFeat.shape[0]\n",
    "indexTrainData = [list(range(1, countTrainData + 1))]\n",
    "\n",
    "# SVM base for invariants\n",
    "\n",
    "# Subset on L_4\n",
    "trainFeat = trainFeat.iloc[:, sindexSVMDATA:eindexSVMDATA + 1]\n",
    "\n",
    "# Join train and test data (separable through indexTrainData in svmFit)\n",
    "tuneFeat = pd.concat([trainFeat, testFeatsub], axis=0)\n",
    "tuneLabel = np.concatenate((trainLabels.values, testLabels.values))\n",
    "\n",
    "validateFeatsub = validateFeatAllLev.iloc[:, sindexSVMDATA:eindexSVMDATA+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "# Expand coarse grid\n",
    "coarse_grid = {'C': 2.0 ** np.arange(-4, 13, 2),\n",
    "                'gamma': 2.0 ** np.arange(-5, 4, 2)}\n",
    "\n",
    "\n",
    "# Coarse grid search\n",
    "svm_coarse = SVC(kernel='rbf')\n",
    "svm_coarse_cv = GridSearchCV(svm_coarse, param_grid=coarse_grid, scoring='accuracy')#, cv=indexTrainData)\n",
    "svm_coarse_cv.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuneFeat.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuneLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand coarse grid\n",
    "coarse_grid = {'C': 2.0 ** np.arange(-4, 13, 2),\n",
    "                'gamma': 2.0 ** np.arange(-5, 4, 2)}\n",
    "\n",
    "# Coarse grid search\n",
    "svm_coarse = SVC(kernel='rbf')\n",
    "svm_coarse_cv = GridSearchCV(svm_coarse, param_grid=coarse_grid, scoring='accuracy')#, cv=indexTrainData)\n",
    "svm_coarse_cv.fit(tuneFeat, tuneLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best coarse grid parameters\n",
    "best_c = svm_coarse_cv.best_params_['C']\n",
    "best_gamma = svm_coarse_cv.best_params_['gamma']\n",
    "\n",
    "# Define narrow grid borders\n",
    "a_gamma = np.log2(best_gamma) - 2\n",
    "b_gamma = np.log2(best_gamma) + 2\n",
    "a_c = np.log2(best_c) - 2\n",
    "b_c = np.log2(best_c) + 2\n",
    "\n",
    "# Expand narrow grid\n",
    "narrow_grid = {'C': 2.0 ** np.arange(a_c, b_c, 0.5),\n",
    "                'gamma': 2.0 ** np.arange(a_gamma, b_gamma, 0.5)}\n",
    "\n",
    "# Narrow grid search\n",
    "svm_narrow = SVC(kernel='rbf')\n",
    "svm_narrow_cv = GridSearchCV(svm_narrow, param_grid=narrow_grid, scoring='accuracy')#, cv=indexTrainData)\n",
    "svm_narrow_cv.fit(tuneFeat, tuneLabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM parameter tuning\n",
    "svm_model=svm_fit(trainFeat, trainLabels, indexTrainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8869384950933479\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict labels of test data\n",
    "predLabelsSVM = svm_model.predict(validateFeatsub)\n",
    "\n",
    "# Accuracy assessment\n",
    "accSVM = accuracy_score(validateLabels, predLabelsSVM)\n",
    "print(accSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataCur.columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VSVM on all Level SV\n",
    "SVindex = svm_model.best_estimator_.support_  # Indices of support vectors\n",
    "SVtotal = trainDataCur.iloc[SVindex, list(range(sindexSVMDATA,eindexSVMDATA+1))+[-1]].reset_index(drop=True)  # Get support vectors\n",
    "\n",
    "SVL2 = trainDataCur.iloc[SVindex, list(range(sindexSVMDATA - 2 * numFeat,sindexSVMDATA - numFeat))+[-1] ].reset_index(drop=True)\n",
    "SVL3 = trainDataCur.iloc[SVindex, list(range(sindexSVMDATA - numFeat,sindexSVMDATA))+[-1] ].reset_index(drop=True)\n",
    "\n",
    "SVL5 = trainDataCur.iloc[SVindex, list(range(sindexSVMDATA + numFeat,sindexSVMDATA + 2 * numFeat))+[-1] ].reset_index(drop=True)\n",
    "SVL6 = trainDataCur.iloc[SVindex, list(range(sindexSVMDATA + 2 * numFeat,sindexSVMDATA + 3 * numFeat))+[-1] ].reset_index(drop=True)\n",
    "SVL7 = trainDataCur.iloc[SVindex, list(range(sindexSVMDATA + 3 * numFeat,sindexSVMDATA + 4 * numFeat))+[-1] ].reset_index(drop=True)\n",
    "SVL8 = trainDataCur.iloc[SVindex, list(range(sindexSVMDATA + 4 * numFeat,sindexSVMDATA + 5 * numFeat))+[-1] ].reset_index(drop=True)\n",
    "SVL9 = trainDataCur.iloc[SVindex, list(range(sindexSVMDATA + 5 * numFeat,sindexSVMDATA + 6 * numFeat))+[-1] ].reset_index(drop=True)\n",
    "SVL10 = trainDataCur.iloc[SVindex, list(range(sindexSVMDATA + 6 * numFeat,sindexSVMDATA + 7 * numFeat))+[-1] ].reset_index(drop=True)\n",
    "SVL11 = trainDataCur.iloc[SVindex, list(range(sindexSVMDATA + 7 * numFeat,sindexSVMDATA + 8 * numFeat))+[-1] ].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Bind original SV with modified to new train data set\n",
    "SVinvar = pd.concat([SVtotal, SVL2, SVL3, SVL5, SVL6, SVL7, SVL8, SVL9, SVL10, SVL11],ignore_index=True)\n",
    "\n",
    "# Split for training to feature and label\n",
    "trainFeatVSVM = SVinvar.iloc[:, :-1].reset_index(drop=True)\n",
    "trainLabelsVSVM = SVinvar.iloc[:, -1]\n",
    "\n",
    "# Get list with index of train data to split between train and test in svmFit\n",
    "countTrainData = SVinvar.shape[0]\n",
    "indexTrainData = [list(range(1, countTrainData + 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalDtype(categories=['bushes_trees', 'other'], ordered=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLabelsVSVM.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lx_g_comp     860\n",
       "Lx_g_elfi     860\n",
       "Lx_g_refi     860\n",
       "Lx_g_roun     860\n",
       "Lx_g_shin     860\n",
       "Lx_m_bl       860\n",
       "Lx_m_gr       860\n",
       "Lx_m_ndvi     860\n",
       "Lx_m_nir      860\n",
       "Lx_m_re       860\n",
       "Lx_sd_bl      860\n",
       "Lx_sd_gr      860\n",
       "Lx_sd_ndvi    860\n",
       "Lx_sd_nir     860\n",
       "Lx_sd_re      860\n",
       "Lx_t_diss     860\n",
       "Lx_t_hom      860\n",
       "Lx_t_mean     860\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFeatVSVM.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lx_g_comp     994\n",
       "Lx_g_elfi     994\n",
       "Lx_g_refi     994\n",
       "Lx_g_roun     994\n",
       "Lx_g_shin     994\n",
       "Lx_m_bl       994\n",
       "Lx_m_gr       994\n",
       "Lx_m_ndvi     994\n",
       "Lx_m_nir      994\n",
       "Lx_m_re       994\n",
       "Lx_sd_bl      994\n",
       "Lx_sd_gr      994\n",
       "Lx_sd_ndvi    994\n",
       "Lx_sd_nir     994\n",
       "Lx_sd_re      994\n",
       "Lx_t_diss     994\n",
       "Lx_t_hom      994\n",
       "Lx_t_mean     994\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuneFeatVSVM.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuneFeatVSVM.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.748004188129832\n"
     ]
    }
   ],
   "source": [
    "# Join of train and test test data (through indexTrainData in svmFit separable)\n",
    "tuneFeatVSVM = pd.concat([trainFeatVSVM, testFeatsub])\n",
    "tuneLabelsVSVM = np.concatenate((trainLabelsVSVM.values, testLabels.values))\n",
    "\n",
    "# VSVM parameter tuning\n",
    "tunedVSVM = svm_fit(tuneFeatVSVM, tuneLabelsVSVM)\n",
    "\n",
    "# Run classification and accuracy assessment for modified SV\n",
    "predLabelsVSVM = tunedVSVM.predict(validateFeatsub)\n",
    "accVSVM = accuracy_score(validateLabels, predLabelsVSVM)\n",
    "print(accVSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(trainFeatVSVM, testFeatsub, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeatVSVM[0:10].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFeatsub[0:10].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([SVtotal,SVL2,SVL5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VSVM - EVALUATION of all Level VSV\n",
    "actKappa = 0\n",
    "bestFittingModel = None\n",
    "\n",
    "# Iteration over bound to test different bound thresholds determining the radius of acceptance\n",
    "for jj in bound:\n",
    "    SVinvarRadi = pd.concat([\n",
    "    rem_extrem(SVtotal, SVL2, jj).set_axis(objInfoNames, axis=1),\n",
    "    rem_extrem(SVtotal, SVL3, jj).set_axis(objInfoNames, axis=1),\n",
    "    rem_extrem(SVtotal, SVL5, jj).set_axis(objInfoNames, axis=1),\n",
    "    rem_extrem(SVtotal, SVL6, jj).set_axis(objInfoNames, axis=1),\n",
    "    rem_extrem(SVtotal, SVL7, jj).set_axis(objInfoNames, axis=1),\n",
    "    rem_extrem(SVtotal, SVL8, jj).set_axis(objInfoNames, axis=1),\n",
    "    rem_extrem(SVtotal, SVL9, jj).set_axis(objInfoNames, axis=1),\n",
    "    rem_extrem(SVtotal, SVL10, jj).set_axis(objInfoNames, axis=1),\n",
    "    rem_extrem(SVtotal, SVL11, jj).set_axis(objInfoNames, axis=1),\n",
    "    # rem_extrem(SVtotal, SVL12, bound[jj]).set_axis(objInfoNames, axis=1),\n",
    "    # rem_extrem(SVtotal, SVL13, bound[jj]).set_axis(objInfoNames, axis=1)\n",
    "    ])    \n",
    "    # Iterating over boundMargin to test different thresholds on margin distance\n",
    "    for kk, bound_margin_val in enumerate(boundMargin):\n",
    "        SVinvar_list = []\n",
    "        \n",
    "        # Iterate over SVinvarRadi and evaluate distance to hyperplane\n",
    "        for m in range(len(SVinvarRadi)):\n",
    "            signa = pred_one(tunedVSVM.finalModel, SVinvarRadi[m, :-1])\n",
    "            if SVinvarRadi[m, -1] == levels(generalDataPool.REF)[0]:\n",
    "                if -bound_margin_val < signa < bound_margin_val:\n",
    "                    SVinvar_list.append(SVinvarRadi[m, :])\n",
    "            else:\n",
    "                if -bound_margin_val < signa < bound_margin_val:\n",
    "                    SVinvar_list.append(SVinvarRadi[m, :])\n",
    "\n",
    "        SVinvar = pd.DataFrame(SVinvar_list, columns=objInfoNames)\n",
    "        \n",
    "        # Merge elected VSV with original SV\n",
    "        SVinvar_org = pd.concat([SVtotal, SVinvar])\n",
    "\n",
    "        # Split for training to feature and label\n",
    "        trainFeatVSVM = SVinvar_org.iloc[:, :-1]\n",
    "        trainLabelsVSVM = SVinvar_org.iloc[:, -1]\n",
    "\n",
    "        # Get list with index of trainData to split between train and test in svmFit\n",
    "        countTrainData = SVinvar_org.shape[0]\n",
    "        indexTrainData = [list(range(1, countTrainData + 1))]\n",
    "\n",
    "        # Join of train and test data (through indexTrainData in svmFit separable)\n",
    "        names = objInfoNames[:-1]\n",
    "        tuneFeatVSVM = pd.concat([trainFeatVSVM, testFeatsub], axis=0)\n",
    "        tuneFeatVSVM.columns = names\n",
    "        tuneLabelsVSVM = np.concatenate((trainLabelsVSVM.values, testLabels.values))\n",
    "\n",
    "        ######################################## VSVM control parameter tuning ########################################\n",
    "        tunedVSVM = SVC(kernel='linear')\n",
    "        tunedVSVM.fit(tuneFeatVSVM, tuneLabelsVSVM)\n",
    "\n",
    "        # Get the best fitting model based on Kappa\n",
    "        if actKappa < tunedVSVM.resample.Kappa:\n",
    "            bestFittingModel = tunedVSVM\n",
    "            actKappa = tunedVSVM.resample.Kappa\n",
    "\n",
    "# Run classification and accuracy assessment for the best bound setting\n",
    "# Predict labels of test data\n",
    "predLabelsVSVMsum = bestFittingModel.predict(validateFeatsub)\n",
    "\n",
    "# Accuracy assessment\n",
    "accVSVM_SL = accuracy_score(validateLabels, predLabelsVSVMsum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Balanced & Random unlabeled samples\n",
    "# Balanced samples\n",
    "\n",
    "# Definition of sampling configuration (strata: random sampling without replacement)\n",
    "stratSampRemaining_b = resample(trainDataCurRemaining, n_samples=[b, b, b, b, b, b], replace=False)\n",
    "samplesRemaining_b = trainDataCurRemaining.iloc[stratSampRemaining_b]\n",
    "\n",
    "trainDataCurRemaining_b = samplesRemaining_b.iloc[:, :-1]\n",
    "trainDataCurRemainingsub_b = trainDataCurRemaining_b.iloc[:, sindexSVMDATA:eindexSVMDATA]\n",
    "REF_b = bestFittingModel.predict(trainDataCurRemainingsub_b)\n",
    "\n",
    "SVindexUn_b = np.arange(1, len(trainDataCurRemainingsub_b) + 1)\n",
    "SVtotalUn_b = trainDataCurRemaining_b.iloc[SVindexUn_b - 1, sindexSVMDATA:eindexSVMDATA]\n",
    "SVtotalUn_b['REF'] = REF_b\n",
    "\n",
    "SVL2Un_b = trainDataCurRemaining.iloc[SVindexUn_b - 1, sindexSVMDATA - 2*numFeat:sindexSVMDATA - numFeat - 1].copy()\n",
    "SVL2Un_b['REF'] = REF_b\n",
    "SVL3Un_b = trainDataCurRemaining.iloc[SVindexUn_b - 1, sindexSVMDATA - numFeat:sindexSVMDATA - 1].copy()\n",
    "SVL3Un_b['REF'] = REF_b\n",
    "SVL5Un_b = trainDataCurRemaining_b.iloc[SVindexUn_b - 1, sindexSVMDATA + numFeat:sindexSVMDATA + 2*numFeat - 1].copy()\n",
    "SVL5Un_b['REF'] = REF_b\n",
    "SVL6Un_b = trainDataCurRemaining_b.iloc[SVindexUn_b - 1, sindexSVMDATA + 2*numFeat:sindexSVMDATA + 3*numFeat - 1].copy()\n",
    "SVL6Un_b['REF'] = REF_b\n",
    "SVL7Un_b = trainDataCurRemaining_b.iloc[SVindexUn_b - 1, sindexSVMDATA + 3*numFeat:sindexSVMDATA + 4*numFeat - 1].copy()\n",
    "SVL7Un_b['REF'] = REF_b\n",
    "SVL8Un_b = trainDataCurRemaining_b.iloc[SVindexUn_b - 1, sindexSVMDATA + 4*numFeat:sindexSVMDATA + 5*numFeat - 1].copy()\n",
    "SVL8Un_b['REF'] = REF_b\n",
    "SVL9Un_b = trainDataCurRemaining_b.iloc[SVindexUn_b - 1, sindexSVMDATA + 5*numFeat:sindexSVMDATA + 6*numFeat - 1].copy()\n",
    "SVL9Un_b['REF'] = REF_b\n",
    "SVL10Un_b = trainDataCurRemaining_b.iloc[SVindexUn_b - 1, sindexSVMDATA + 6*numFeat:sindexSVMDATA + 7*numFeat - 1].copy()\n",
    "SVL10Un_b['REF'] = REF_b\n",
    "SVL11Un_b = trainDataCurRemaining_b.iloc[SVindexUn_b - 1, sindexSVMDATA + 7*numFeat:sindexSVMDATA + 8*numFeat - 1].copy()\n",
    "SVL11Un_b['REF'] = REF_b\n",
    "\n",
    "SVinvarUn_b = pd.concat([SVtotalUn_b, SVL2Un_b, SVL3Un_b, SVL5Un_b, SVL6Un_b, SVL7Un_b, SVL8Un_b, SVL9Un_b, SVL10Un_b, SVL11Un_b])\n",
    "\n",
    "# Balanced Unlabeled samples\n",
    "\n",
    "actKappa = 0\n",
    "\n",
    "for jj in range(len(bound)):\n",
    "    SVinvarRadiUn_b_list = []\n",
    "    for m in range(len(SVinvarRadiUn_b)):\n",
    "        signa = pred_one(tunedSVM.finalModel, SVinvarRadiUn_b.iloc[m, :-1])\n",
    "        if SVinvarRadiUn_b.iloc[m, -1] == levels(generalDataPool.REF)[0]:\n",
    "            if -bound_margin_val < signa < bound_margin_val:\n",
    "                SVinvarRadiUn_b_list.append(SVinvarRadiUn_b.iloc[m, :])\n",
    "        else:\n",
    "            if -bound_margin_val < signa < bound_margin_val:\n",
    "                SVinvarRadiUn_b_list.append(SVinvarRadiUn_b.iloc[m, :])\n",
    "\n",
    "    SVinvarUn_b = pd.DataFrame(SVinvarRadiUn_b_list, columns=objInfoNames)\n",
    "    \n",
    "    SVinvar_orgUn_b = pd.concat([SVtotal, SVinvarUn_b])\n",
    "\n",
    "    trainFeatVSVMUn_b = SVinvar_orgUn_b.iloc[:, :-1]\n",
    "    trainLabelsVSVMUn_b = SVinvar_orgUn_b.iloc[:, -1]\n",
    "\n",
    "    countTrainDataUn_b = SVinvar_orgUn_b.shape[0]\n",
    "    indexTrainDataUn_b = [list(range(1, countTrainDataUn_b + 1))]\n",
    "\n",
    "    names = objInfoNames[:-1]\n",
    "    tuneFeatVSVMUn_b = pd.concat([trainFeatVSVMUn_b, testFeatsub], axis=0)\n",
    "    tuneFeatVSVMUn_b.columns = names\n",
    "    tuneLabelsVSVMUn_b = np.concatenate((trainLabelsVSVMUn_b.values, testLabels.values))\n",
    "\n",
    "    tunedVSVMUn_b = SVC(kernel='linear')\n",
    "    tunedVSVMUn_b.fit(tuneFeatVSVMUn_b, tuneLabelsVSVMUn_b)\n",
    "\n",
    "    if actKappa < tunedVSVMUn_b.resample.Kappa:\n",
    "        bestFittingModelUn_b = tunedVSVMUn_b\n",
    "        actKappa = tunedVSVMUn_b.resample.Kappa\n",
    "\n",
    "# Run classification and accuracy assessment for the best bound setting\n",
    "predLabelsVSVMsumUn_b = bestFittingModelUn_b.predict(validateFeatsub)\n",
    "\n",
    "# Accuracy assessment\n",
    "accVSVM_SL_Un_b = accuracy_score(validateLabels, predLabelsVSVMsumUn_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predicted labels to the features data set\n",
    "predLabelsVSVMsumUn_unc = pd.concat([validateFeatsub, pd.DataFrame(predLabelsVSVMsumUn_b, columns=[\"Predicted_Labels\"])], axis=1)\n",
    "predLabelsVSVMsumUn_unc.columns = objInfoNames\n",
    "\n",
    "# Calculate uncertainty of the samples by selecting SV's and data set\n",
    "normdistvsvm_sl_un = uncertainty_dist_v2_2(bestFittingModelUn_b, predLabelsVSVMsumUn_unc)\n",
    "\n",
    "# Alter labels\n",
    "predlabels_vsvm_Slu = alter_labels(normdistvsvm_sl_un, validateLabels)\n",
    "\n",
    "# Accuracy assessment\n",
    "accVSVM_SL_Un_b_ad = accuracy_score(validateLabels, predlabels_vsvm_Slu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
