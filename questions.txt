row 436 #P: we already did this at row 421-426
row 550 #P: check in 2Class Setting only first two records are used BY DEFAULT
row 637 #P: we can remove the redundancy then?
row 636 #P: yes but SOME of this data are used before for training/test/validate, right? 
row 738 #P: just for confirmation, the trainFeatVSVM is made only by VSVs?
roe 770 #P: we should keep the Random, but for the sake of balanced train set we use Balanced
row 36  trainControl -> how does actually work with the indexTrain
row 197 rbf_kernel -> that I added is required, right?
row 371 abs(pred) -> for the distance we need only positive values, right? (I added abs)
row 603 ref_added_or[1:250,]$distance = 1 -> which are the actual values for the distance? after norm, the max value 1
row 956 binaryClassProblem 
In svm what is the difference between probability class and distance class? see both related paper and script function

check the values inside the computed vectors
check the accuracies

how to improve performance 
 - check how many CPU cores are present on the RSRG server and how to use them
 - vectorize: apply() {R function} + predict() {kernlab function} 

****************************************************************
library(foreach)
library(doParallel)
x <- iris[which(iris[,5] != "setosa"), c(1,5)]
trials <- 10000
registerDoParallel(cores=2)
ptime <- system.time({
r <- foreach(icount(trials), .combine=cbind) %dopar% {
ind <- sample(100, 100, replace=TRUE)
result1 <- glm(x[ind,2]~x[ind,1], family=binomial(logit))
coefficients(result1)
}
})
ptime

stime <- system.time({
r <- foreach(icount(trials), .combine=cbind) %do% {
result1 <- glm(x[ind,2]~x[ind,1], family=binomial(logit))
oefficients(result1)
}
})
stime
****************************************************************

 1.  DONE try without indexTrain  
 2.  perform PCA / t-SNE
 3.  WIP split alter_samples in multiple iterations 
 4.  DONE check if in the multiclas setting the random / balanced unlabeled samples actually change
 5.  DONE implement only_probability_distance + check different implementation of mclu (see paper) 
 6.  DONE check if NDVI feature is actually useful
 7.  focus on meadow and other_impervious_surface classes (they have less labels)
 8.  DONE implement binary + multiclass in the same script
 9.  tune alter_label hyperparameter: how many label need to be relabeled?
 10.a overall hyperparameters optimization e.g. "boundMargin" and "bound" 
 10.b how to parallelize EVALUATION of all Level VSV to increase "boundMargin" and "bound"
 11. DONE descriptive stats of the dataset/data visualization
 12. k score value definition: see what happens if we use acc instead
 13. check why if(!tmp_cond){VSV1[k,]=NA} in rem_extrem_kerneldist doesn't work
 14. one vs all VSM Classification instead of binarymulticlass
 15. why multiclass script is implemented differently from the binary ones and got different accuracies

 Lu et al.(2016): A Novel Synergetic Classification Approach for  Hyperspectral and Panchromatic Images Based on Self-Learning

library(AppliedPredictiveModeling)
transparentTheme(trans = .9)
featurePlot(x = tuneFeat[, 8:10], 
             y = tuneLabel, 
             plot = "ellipse",
             ## Add a key at the top
             auto.key = list(columns = 3))
featurePlot(x = tuneFeat[, 7:10], 
             y = tuneLabel,
             plot = "density", 
             scales = list(x = list(relation="free"), 
                           y = list(relation="free")), 
             adjust = 1.5, 
             pch = "|", 
             layout = c(4, 1), 
             auto.key = list(columns = 3))