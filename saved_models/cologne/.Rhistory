geom_point(size = 3) +
labs(title = "K-means Clustering on PCA",
x = "Principal Component 1",
y = "Principal Component 2") +
theme_minimal()
# cluster_colors <- rainbow(length(unique(pca_data$Cluster)))
# # Plotting PC1 vs PC2 with different colors for each cluster
# plot( pca_data$PC1,ref_added_or[, 21], col = cluster_colors[pca_data$Cluster],
#      pch = 20, cex = 2, main = "K-means Clustering on PCA",
#      xlab = "Principal Component 1", ylab = "Distance")
# legend("right", legend = levels(pca_data$Cluster), col = cluster_colors, pch = 20,
#        title = "Cluster",xpd = TRUE, bty = "n")
# # Perform k-means clustering
# km_result <- kmeans(ref_added_or[, 1:18], centers = cluster, iter.max = 25, nstart = 200)
# Add cluster information to the data
ref_added_or$cluster <- km_result$cluster
# Initialize a vector to store selected sample indices
selected_indices <- c()
cluster_samples <- c()
tmpSize = 0
# Iterate over clusters and select one sample from each cluster
for (sample in seq_len(nrow(ref_added_or))) {
if (!( ref_added_or[sample,]$cluster  %in% cluster_samples) && tmpSize < newSize){
cluster_samples <- c(cluster_samples, ref_added_or[sample,]$cluster)
tmpSize = tmpSize+1
ref_added_or[sample,]$label <- ref_added_or[sample,]$ref
selected_indices <- c(selected_indices, as.numeric(rownames(ref_added_or[sample,])))
}
}
ref_added_reor = ref_added_or[order(as.numeric(rownames(ref_added_or))),]
# Add relabeled samples to new_trainFeatVSVM and new_trainLabelsVSVM
if(length(features)>1){
# Remove relabeled samples from validateLabels
features <- features[!(rownames(features) %in% selected_indices), ]
reor_idx <- which(rownames(ref_added_reor) %in% selected_indices)
ref <- ref[-reor_idx]
new_trainFeatVSVM <- ref_added_reor[reor_idx, 1:(ncol(ref_added_reor)-5)]
new_trainLabelsVSVM <- ref_added_reor[reor_idx, (ncol(ref_added_reor)-4)]
ID_unit <- ID_unit[reor_idx]
return(list(features = features, labels = ref, IDunit=ID_unit,
new_trainFeatVSVM = new_trainFeatVSVM,
new_trainLabelsVSVM = new_trainLabelsVSVM))
} else{
return(ref_added_reor[, (ncol(ref_added_reor)-4)])
}
}
confusionMatrix(new_trainLabels,predict(bestFittingModel, new_trainFeat))
# print(paste0("Iteration ",iter,"/",num_iters,"..."))
predLabelsVSVM = predict(tmp_new_tunedSVM, upd_dataCurFeatsub)
# Add predicted labels to the features data set
predLabelsVSVM_unc = cbind(upd_dataCurFeatsub, predLabelsVSVM)
predLabelsVSVM_unc = setNames(predLabelsVSVM_unc, objInfoNames)
# print(paste0("Computing distances..."))
if(model_prob=="binary"){sampled_data <- margin_sampling(tmp_new_tunedSVM, predLabelsVSVM_unc, pred_one, binaryClassProblem)
}else{                   sampled_data <- mclu_sampling(tmp_new_tunedSVM, predLabelsVSVM_unc, pred_all, binaryClassProblem) }
# print(paste0("Relabeling samples..."))
# Get new labels and updated datasets
result <- add_new_samples_AL(sampled_data,
upd_dataCurLabels, upd_dataCurFeatsub, upd_dataCur$ID_unit,
new_trainFeatVSVM, new_trainLabelsVSVM,
newSize_for_iter,
clusterSizes[cS] ) # always greater than newSize_for_iter, # 60, 80, 100, 120
source("D:/GitHub/active-learning-virtual-SVM/AL_VSVMSL.R", echo=TRUE)
sampleSizePor = c(20)
resampledSize = c(2*b)
newSizes = c(2*b)
# classSize = c(100*b)
clusterSizes = c(2*b)
if(num_cores>=4){
print(paste0("computing uncertainty distance for active learning procedure... [",realization,"/",nR,"] | ",sampleSizePor[sample_size]*2," [",sample_size,"/",length(sampleSizePor),"]"))
actAcc = -1e-6
classSize=c(min(240*b,round(as.numeric(min(table(trainDataCurRemaining$REF)))/1)))
for(clS in 1:length(classSize)){
stratSampSize = c(classSize[clS],classSize[clS],classSize[clS],classSize[clS],classSize[clS],classSize[clS])
# Definition of sampling configuration (strata:random sampling without replacement)
stratSampRemaining = strata(trainDataCurRemaining, c("REF"), size = stratSampSize, method = "srswor")
# Get new samples from trainDataCurRemaining
samplesRemaining = getdata(trainDataCurRemaining, stratSampRemaining)
# trainDataCurRemaining <- trainDataCurRemaining[-c(samplesRemaining$ID_unit), ]
for(cS in 1:length(clusterSizes)){
for(rS in 1:length(resampledSize)){
for(nS4it in 1:length(newSizes)){
print(paste0("sampled: ",resampledSize[rS]," [",rS,"/",length(resampledSize),"] | samples/iter: ",newSizes[nS4it]," [",nS4it,"/",length(newSizes),"] | pool/class: ",classSize[clS]," [",clS,"/",length(classSize),"] | clusters: ",clusterSizes[cS]," [",cS,"/",length(clusterSizes),"]"))
upd_dataCur <- samplesRemaining[,1:(ncol(trainDataCur)+1)]
upd_dataCurFeatsub <- upd_dataCur[,c(sindexSVMDATA:eindexSVMDATA)]
upd_dataCurLabels <- upd_dataCur[,ncol(trainDataCur)]
# new_trainFeatVSVM <- setNames(trainFeat, names)
# new_trainLabelsVSVM <- trainLabels
# tmp_new_tunedSVM <- tunedSVM
new_trainFeatVSVM <- setNames(best_trainFeatVSVM, names)
new_trainLabelsVSVM <- best_trainLabelsVSVM
tmp_new_tunedSVM <- bestFittingModel
newSize_for_iter = newSizes[rS] #sampleSize/10 # or just 4
num_iters = round(resampledSize[rS]/newSize_for_iter) # 1, 3, 5, 10, 16, 24, 50, 100
trainStart.time <- Sys.time()
for (iter in 1:num_iters){
# print(paste0("Iteration ",iter,"/",num_iters,"..."))
predLabelsVSVM = predict(tmp_new_tunedSVM, upd_dataCurFeatsub)
# Add predicted labels to the features data set
predLabelsVSVM_unc = cbind(upd_dataCurFeatsub, predLabelsVSVM)
predLabelsVSVM_unc = setNames(predLabelsVSVM_unc, objInfoNames)
# print(paste0("Computing distances..."))
if(model_prob=="binary"){sampled_data <- margin_sampling(tmp_new_tunedSVM, predLabelsVSVM_unc, pred_one, binaryClassProblem)
}else{                   sampled_data <- mclu_sampling(tmp_new_tunedSVM, predLabelsVSVM_unc, pred_all, binaryClassProblem) }
# print(paste0("Relabeling samples..."))
# Get new labels and updated datasets
result <- add_new_samples_AL(sampled_data,
upd_dataCurLabels, upd_dataCurFeatsub, upd_dataCur$ID_unit,
new_trainFeatVSVM, new_trainLabelsVSVM,
newSize_for_iter,
clusterSizes[cS] ) # always greater than newSize_for_iter, # 60, 80, 100, 120
# Extract new datasets
upd_dataCurFeatsub <- result$features
upd_dataCurLabels <- result$labels
# get SV of labeled samples
upd_SVindex_ud = upd_dataCur$ID_unit %in% result$IDunit
new_trainFeat <- result$new_trainFeatVSVM
new_trainLabels <- result$new_trainLabelsVSVM
# **********************
# get original SVs of base SVM
SVindex_ud = tmp_new_tunedSVM$finalModel@SVindex
# SVindex_ud = 1:nrow(new_trainFeatVSVM)
new_trainFeatVSVM=new_trainFeatVSVM[SVindex_ud,]
new_trainLabelsVSVM=new_trainLabelsVSVM[SVindex_ud]
new_trainFeatVSVM <- rbind(new_trainFeatVSVM, setNames(new_trainFeat, names))
new_trainLabelsVSVM <- unlist(list(new_trainLabelsVSVM, new_trainLabels))
SVtotal = setNames(cbind(new_trainFeatVSVM, new_trainLabelsVSVM),c(objInfoNames[-length(objInfoNames)],"REF"))
# **********************
# REF_ud = predict(tmp_new_tunedSVM, new_trainFeat)
REF_ud = new_trainLabels
# confusionMatrix(new_trainLabels,predict(bestFittingModel, new_trainFeat))
SVtotal_ud = cbind(new_trainFeat, REF_ud)
if(invariance=="scale"){
if(city=="cologne"){
SVL_variables = list(
# list(SVtotal, SVL2 = trainDataCur[SVindex,c((sindexSVMDATA - 2*numFeat):(sindexSVMDATA - numFeat - 1), ncol(trainDataCur))]),
# list(SVtotal, SVL3 = trainDataCur[SVindex,c((sindexSVMDATA - numFeat):(sindexSVMDATA -1), ncol(trainDataCur))]),
# list(SVtotal, SVL5 = trainDataCur[SVindex,c((sindexSVMDATA + numFeat):((sindexSVMDATA + 2*numFeat)-1),ncol(trainDataCur))]),
# list(SVtotal, SVL6 = trainDataCur[SVindex,c((sindexSVMDATA + 2*numFeat):((sindexSVMDATA + 3*numFeat)-1),ncol(trainDataCur))]),
# list(SVtotal, SVL7 = trainDataCur[SVindex,c((sindexSVMDATA + 3*numFeat):((sindexSVMDATA + 4*numFeat)-1),ncol(trainDataCur))]),
# list(SVtotal, SVL8 = trainDataCur[SVindex,c((sindexSVMDATA + 4*numFeat):((sindexSVMDATA + 5*numFeat)-1),ncol(trainDataCur))]),
# list(SVtotal, SVL9 = trainDataCur[SVindex,c((sindexSVMDATA + 5*numFeat):((sindexSVMDATA + 6*numFeat)-1),ncol(trainDataCur))]),
# list(SVtotal, SVL10 = trainDataCur[SVindex,c((sindexSVMDATA + 6*numFeat):((sindexSVMDATA + 7*numFeat)-1),ncol(trainDataCur))]),
# list(SVtotal, SVL11 = trainDataCur[SVindex,c((sindexSVMDATA + 7*numFeat):((sindexSVMDATA + 8*numFeat)-1),ncol(trainDataCur))]),
list(SVtotal_ud, SVL2=cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA - 2*numFeat):(sindexSVMDATA - numFeat - 1))],REF_ud)),
list(SVtotal_ud, SVL3=cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA - numFeat):(sindexSVMDATA -1))],REF_ud)),
list(SVtotal_ud, SVL5=cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + numFeat):((sindexSVMDATA + 2*numFeat)-1))],REF_ud)),
list(SVtotal_ud, SVL6=cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + 2*numFeat):((sindexSVMDATA + 3*numFeat)-1))],REF_ud)),
list(SVtotal_ud, SVL7=cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + 3*numFeat):((sindexSVMDATA + 4*numFeat)-1))],REF_ud)),
list(SVtotal_ud, SVL8=cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + 4*numFeat):((sindexSVMDATA + 5*numFeat)-1))],REF_ud)),
list(SVtotal_ud, SVL9=cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + 5*numFeat):((sindexSVMDATA + 6*numFeat)-1))],REF_ud)),
list(SVtotal_ud, SVL10=cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + 6*numFeat):((sindexSVMDATA + 7*numFeat)-1))],REF_ud)),
list(SVtotal_ud, SVL11=cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + 7*numFeat):((sindexSVMDATA + 8*numFeat)-1))],REF_ud))
)
}else{
SVL_variables = list(
# list(SVtotal, SVL2 = trainDataCur[SVindex,c((sindexSVMDATA - 2*numFeat):(sindexSVMDATA - numFeat - 1), ncol(trainDataCur))]),
# list(SVtotal, SVL3 = trainDataCur[SVindex,c((sindexSVMDATA - numFeat):(sindexSVMDATA -1), ncol(trainDataCur))]),
# list(SVtotal, SVL5 = trainDataCur[SVindex,c((sindexSVMDATA + numFeat):((sindexSVMDATA + 2*numFeat)-1),ncol(trainDataCur))]),
# list(SVtotal, SVL6 = trainDataCur[SVindex,c((sindexSVMDATA + 2*numFeat):((sindexSVMDATA + 3*numFeat)-1),ncol(trainDataCur))]),
# list(SVtotal, SVL7 = trainDataCur[SVindex,c((sindexSVMDATA + 3*numFeat):((sindexSVMDATA + 4*numFeat)-1),ncol(trainDataCur))]),
# list(SVtotal, SVL8 = trainDataCur[SVindex,c((sindexSVMDATA + 4*numFeat):((sindexSVMDATA + 5*numFeat)-1),ncol(trainDataCur))]),
# list(SVtotal, SVL9 = trainDataCur[SVindex,c((sindexSVMDATA + 5*numFeat):((sindexSVMDATA + 6*numFeat)-1),ncol(trainDataCur))]),
list(SVtotal_ud, SVL2=(cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA - 2*numFeat):(sindexSVMDATA - numFeat - 1))],REF_ud))),
list(SVtotal_ud, SVL3=(cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA - numFeat):(sindexSVMDATA -1))],REF_ud))),
list(SVtotal_ud, SVL5=(cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + numFeat):((sindexSVMDATA + 2*numFeat)-1))],REF_ud))),
list(SVtotal_ud, SVL6=(cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + 2*numFeat):((sindexSVMDATA + 3*numFeat)-1))],REF_ud))),
list(SVtotal_ud, SVL7=(cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + 3*numFeat):((sindexSVMDATA + 4*numFeat)-1))],REF_ud))),
list(SVtotal_ud, SVL8=(cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + 4*numFeat):((sindexSVMDATA + 5*numFeat)-1))],REF_ud))),
list(SVtotal_ud, SVL9=(cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + 5*numFeat):((sindexSVMDATA + 6*numFeat)-1))],REF_ud)))
)
}
}else{
SVL_variables = list(
# list(SVtotal, trainDataCur[SVindex,c((numFeat+1):(2*numFeat),ncol(trainDataCur))]),
# list(SVtotal, trainDataCur[SVindex,c(((2*numFeat)+1):(3*numFeat),ncol(trainDataCur))]),
# list(SVtotal, trainDataCur[SVindex,c(((3*numFeat)+1):(4*numFeat),ncol(trainDataCur))]),
# list(SVtotal, trainDataCur[SVindex,c(((4*numFeat)+1):(5*numFeat),ncol(trainDataCur))]),
# list(SVtotal, trainDataCur[SVindex,c(((5*numFeat)+1):(6*numFeat),ncol(trainDataCur))]),
# list(SVtotal, trainDataCur[SVindex,c(((6*numFeat)+1):(7*numFeat),ncol(trainDataCur))]),
# list(SVtotal, trainDataCur[SVindex,c(((7*numFeat)+1):(8*numFeat),ncol(trainDataCur))]),
# list(SVtotal, trainDataCur[SVindex,c(((8*numFeat)+1):(9*numFeat),ncol(trainDataCur))]),
list(SVtotal_ud, S01C09=(cbind(upd_dataCur[upd_SVindex_ud,c((numFeat+1):(2*numFeat))],REF_ud))),
list(SVtotal_ud, S03C05=(cbind(upd_dataCur[upd_SVindex_ud,c(((2*numFeat)+1):(3*numFeat))],REF_ud))),
list(SVtotal_ud, S03C07=(cbind(upd_dataCur[upd_SVindex_ud,c(((3*numFeat)+1):(4*numFeat))],REF_ud))),
list(SVtotal_ud, S05C03=(cbind(upd_dataCur[upd_SVindex_ud,c(((4*numFeat)+1):(5*numFeat))],REF_ud))),
list(SVtotal_ud, S05C05=(cbind(upd_dataCur[upd_SVindex_ud,c(((5*numFeat)+1):(6*numFeat))],REF_ud))),
list(SVtotal_ud, S05C07=(cbind(upd_dataCur[upd_SVindex_ud,c(((6*numFeat)+1):(7*numFeat))],REF_ud))),
list(SVtotal_ud, S07C03=(cbind(upd_dataCur[upd_SVindex_ud,c(((7*numFeat)+1):(8*numFeat))],REF_ud))),
list(SVtotal_ud, S09C01=(cbind(upd_dataCur[upd_SVindex_ud,c(((8*numFeat)+1):(9*numFeat))],REF_ud)))
)
} #
upd_SLresult <- self_learn(testFeatsub, testLabels, bound = c(0.05, 0.1, 0.3), boundMargin = c(0.5, 0.3, 0.2), model_name_AL_VSVMSL, SVtotal, objInfoNames,rem_extrem,rem_extrem_kerneldist, #classProb=TRUE,
SVL_variables, tmp_new_tunedSVM$finalModel)
tmp_new_tunedSVM <- upd_SLresult$bestFittingModel
new_trainFeatVSVM <- upd_SLresult$best_trainFeatVSVM
new_trainLabelsVSVM <- as.character(upd_SLresult$best_trainLabelsVSVM)
# length(best_trainLabelsVSVM)
# length(bestFittingModel$finalModel@SVindex)
# length(new_trainLabels)
# length(new_trainLabelsVSVM)
# new_trainFeatVSVM <- rbind(new_trainFeatVSVM, setNames(new_trainFeat, names))
# new_trainLabelsVSVM <- unlist(list(new_trainLabelsVSVM, new_trainLabels))
# # Get list with index of trainData to split between train and test in svmFit
# countTrainDataUn = nrow(new_trainFeatVSVM)
# indexTrainDataUn_it = list(c(1:countTrainDataUn))
# # Join of train and test data (seperable in svmFit through indexes)
# tuneFeatVSVMUn_it = rbind(new_trainFeatVSVM, setNames(testFeatsub, names))
# tuneLabelsVSVMUn_it = unlist(list(new_trainLabelsVSVM, testLabels))
# tmp_new_tunedSVM = svmFit(tuneFeatVSVMUn_it, tuneLabelsVSVMUn_it, indexTrainDataUn_it, showPrg = FALSE)
upd_dataCur <- upd_dataCur[-c(result$IDunit), ]
}
t.time <- round(as.numeric((Sys.time() - trainStart.time), units = "secs"), 3)
tmp_pred = predict(tmp_new_tunedSVM, validateFeatsub)
tmp_acc  = confusionMatrix(tmp_pred, validateLabels)
# if(actAcc < tmp_new_tunedSVM$resample$Kappa){ print(paste0("current best kappa: ",round(tmp_new_tunedSVM$resample$Kappa,4)))
if(actAcc < tmp_acc$overall["Accuracy"]){ print(paste0("current best accuracy: ",round(tmp_acc$overall["Accuracy"],5)," | related kappa: ",round(tmp_new_tunedSVM$resample$Kappa,4)))
new_tunedSVM = tmp_new_tunedSVM
actAcc = tmp_acc$overall["Accuracy"] # tmp_new_tunedSVM$resample$Kappa #
best_resample = resampledSize[rS]
best_newSize4iter = newSizes[nS4it]
best_classSize = classSize[clS]
best_cluster = clusterSizes[cS]
train.time = t.time
}
}
}
}
}
fin_predLabelsVSVM_SL_itAL = predict(new_tunedSVM, validateFeatsub)
accVSVM_SL_itAL  = confusionMatrix(fin_predLabelsVSVM_SL_itAL, validateLabels)
print(paste0("VSVM_SL - AL accuracy: ",round(accVSVM_SL_itAL$overall["Accuracy"],5)," | training time: ",train.time,"sec"))
if(actAcc>best_acc){
best_acc <- actAcc
best_model <- model_name_AL_VSVMSL
}
gc()
AccuracyVSVM_SL_Un_it[realization,sample_size] = as.numeric(accVSVM_SL_itAL$overall["Accuracy"])
# AccuracyVSVM_SL_Un_b_ud[realization,sample_size] = as.numeric(accVSVM_SL_Un_b_ud$overall["Accuracy"])
# AccuracyVSVM_SL_Un_b_ms[realization,sample_size] = as.numeric(accVSVM_SL_Un_b_ms$overall["Accuracy"])
# AccuracyVSVM_SL_Un_b_mclu[realization,sample_size] = as.numeric(accVSVM_SL_Un_b_mclu$overall["Accuracy"])
# AccuracyVSVM_SL_Un_b_mclp[realization,sample_size] = as.numeric(accVSVM_SL_Un_b_mclp$overall["Accuracy"])
KappaVSVM_SL_Un_it[realization,sample_size] = as.numeric(accVSVM_SL_itAL$overall["Kappa"])
# KappaVSVM_SL_Un_b_ud[realization,sample_size] = as.numeric(accVSVM_SL_Un_b_ud$overall["Kappa"])
# KappaVSVM_SL_Un_b_ms[realization,sample_size] = as.numeric(accVSVM_SL_Un_b_ms$overall["Kappa"])
# KappaVSVM_SL_Un_b_mclu[realization,sample_size] = as.numeric(accVSVM_SL_Un_b_mclu$overall["Kappa"])
# KappaVSVM_SL_Un_b_mclp[realization,sample_size] = as.numeric(accVSVM_SL_Un_b_mclp$overall["Kappa"])
}
# add_new_samples_AL(distance_data=sampled_data,
#                    ref=upd_dataCurLabels, features=upd_dataCurFeatsub, ID_unit=upd_dataCur$ID_unit,
#                    new_trainFeatVSVM, new_trainLabelsVSVM,
#                    newSize=newSize_for_iter,
#                    cluster=clusterSizes[cS] )
add_new_samples_AL = function(distance_data,
ref, features=NA,ID_unit,
new_trainFeatVSVM=NA, new_trainLabelsVSVM=NA,
newSize=4, cluster=5){
if(cluster<newSize){cluster=round(newSize*1.01)}
# merge features and original labels
ref_added = cbind(distance_data, ref)
# order by most uncertain samples
ref_added_or = ref_added[order(ref_added$distance),]
# Perform PCA using prcomp from stats library
pca_result <- prcomp(ref_added_or[, 1:18], center = TRUE, scale. = TRUE)
# Extract the first two principal components
pca_data <- data.frame(pca_result$x[, 1:2])
colnames(pca_data) <- c("PC1", "PC2")
ref_data_with_distance <- cbind(ref_added_or[, 1:18], ref_added_or[, 21])
# wss <- (nrow(ref_data_with_distance) - 1) * sum(apply(ref_data_with_distance, 2, var))
wss <- sum(kmeans(ref_data_with_distance, centers = 10)$tot.withinss)
for (i in 1:30) wss[i+1] <- sum(kmeans(ref_data_with_distance, centers = i+10, iter.max = 15, nstart = 50)$tot.withinss)
plot(10:40, wss, type = "b", xlab = "Number of Clusters", ylab = "Within groups sum of squares")
# Apply k-means clustering
km_result <- kmeans(ref_data_with_distance, centers = cluster, iter.max = 25, nstart = 50)
# Add the cluster assignments to the pca_data dataframe
pca_data$Cluster <- as.factor(km_result$cluster)
# # Plot the first two principal components with k-means clusters
# ggplot(pca_data, aes(x = PC1, y = PC2, color = Cluster)) +
#   geom_point(size = 3) +
#   labs(title = "K-means Clustering on PCA",
#        x = "Principal Component 1",
#        y = "Principal Component 2") +
#   theme_minimal()
cluster_colors <- rainbow(length(unique(pca_data$Cluster)))
# Plotting PC1 vs PC2 with different colors for each cluster
plot( pca_data$PC1,ref_added_or[, 21], col = cluster_colors[pca_data$Cluster],
pch = 20, cex = 2, main = "K-means Clustering on PCA",
xlab = "Principal Component 1", ylab = "Distance")
legend("right", legend = levels(pca_data$Cluster), col = cluster_colors, pch = 20,
title = "Cluster",xpd = TRUE, bty = "n")
# # Perform k-means clustering
# km_result <- kmeans(ref_added_or[, 1:18], centers = cluster, iter.max = 25, nstart = 200)
# Add cluster information to the data
ref_added_or$cluster <- km_result$cluster
# Initialize a vector to store selected sample indices
selected_indices <- c()
cluster_samples <- c()
tmpSize = 0
# Iterate over clusters and select one sample from each cluster
for (sample in seq_len(nrow(ref_added_or))) {
if (!( ref_added_or[sample,]$cluster  %in% cluster_samples) && tmpSize < newSize){
cluster_samples <- c(cluster_samples, ref_added_or[sample,]$cluster)
tmpSize = tmpSize+1
ref_added_or[sample,]$label <- ref_added_or[sample,]$ref
selected_indices <- c(selected_indices, as.numeric(rownames(ref_added_or[sample,])))
}
}
ref_added_reor = ref_added_or[order(as.numeric(rownames(ref_added_or))),]
# Add relabeled samples to new_trainFeatVSVM and new_trainLabelsVSVM
if(length(features)>1){
# Remove relabeled samples from validateLabels
features <- features[!(rownames(features) %in% selected_indices), ]
reor_idx <- which(rownames(ref_added_reor) %in% selected_indices)
ref <- ref[-reor_idx]
new_trainFeatVSVM <- ref_added_reor[reor_idx, 1:(ncol(ref_added_reor)-5)]
new_trainLabelsVSVM <- ref_added_reor[reor_idx, (ncol(ref_added_reor)-4)]
ID_unit <- ID_unit[reor_idx]
return(list(features = features, labels = ref, IDunit=ID_unit,
new_trainFeatVSVM = new_trainFeatVSVM,
new_trainLabelsVSVM = new_trainLabelsVSVM))
} else{
return(ref_added_reor[, (ncol(ref_added_reor)-4)])
}
}
1.85*b
resampledSize = c(0.5*b)
newSizes = c(0.5*b)
# classSize = c(100*b)
clusterSizes = c(0.55*b)
if(num_cores>=4){
print(paste0("computing uncertainty distance for active learning procedure... [",realization,"/",nR,"] | ",sampleSizePor[sample_size]*2," [",sample_size,"/",length(sampleSizePor),"]"))
actAcc = -1e-6
classSize=c(min(240*b,round(as.numeric(min(table(trainDataCurRemaining$REF)))/1)))
for(clS in 1:length(classSize)){
stratSampSize = c(classSize[clS],classSize[clS],classSize[clS],classSize[clS],classSize[clS],classSize[clS])
# Definition of sampling configuration (strata:random sampling without replacement)
stratSampRemaining = strata(trainDataCurRemaining, c("REF"), size = stratSampSize, method = "srswor")
# Get new samples from trainDataCurRemaining
samplesRemaining = getdata(trainDataCurRemaining, stratSampRemaining)
# trainDataCurRemaining <- trainDataCurRemaining[-c(samplesRemaining$ID_unit), ]
for(cS in 1:length(clusterSizes)){
for(rS in 1:length(resampledSize)){
for(nS4it in 1:length(newSizes)){
print(paste0("sampled: ",resampledSize[rS]," [",rS,"/",length(resampledSize),"] | samples/iter: ",newSizes[nS4it]," [",nS4it,"/",length(newSizes),"] | pool/class: ",classSize[clS]," [",clS,"/",length(classSize),"] | clusters: ",clusterSizes[cS]," [",cS,"/",length(clusterSizes),"]"))
upd_dataCur <- samplesRemaining[,1:(ncol(trainDataCur)+1)]
upd_dataCurFeatsub <- upd_dataCur[,c(sindexSVMDATA:eindexSVMDATA)]
upd_dataCurLabels <- upd_dataCur[,ncol(trainDataCur)]
# new_trainFeatVSVM <- setNames(trainFeat, names)
# new_trainLabelsVSVM <- trainLabels
# tmp_new_tunedSVM <- tunedSVM
new_trainFeatVSVM <- setNames(best_trainFeatVSVM, names)
new_trainLabelsVSVM <- best_trainLabelsVSVM
tmp_new_tunedSVM <- bestFittingModel
newSize_for_iter = newSizes[rS] #sampleSize/10 # or just 4
num_iters = round(resampledSize[rS]/newSize_for_iter) # 1, 3, 5, 10, 16, 24, 50, 100
trainStart.time <- Sys.time()
for (iter in 1:num_iters){
# print(paste0("Iteration ",iter,"/",num_iters,"..."))
predLabelsVSVM = predict(tmp_new_tunedSVM, upd_dataCurFeatsub)
# Add predicted labels to the features data set
predLabelsVSVM_unc = cbind(upd_dataCurFeatsub, predLabelsVSVM)
predLabelsVSVM_unc = setNames(predLabelsVSVM_unc, objInfoNames)
# print(paste0("Computing distances..."))
if(model_prob=="binary"){sampled_data <- margin_sampling(tmp_new_tunedSVM, predLabelsVSVM_unc, pred_one, binaryClassProblem)
}else{                   sampled_data <- mclu_sampling(tmp_new_tunedSVM, predLabelsVSVM_unc, pred_all, binaryClassProblem) }
# print(paste0("Relabeling samples..."))
# Get new labels and updated datasets
result <- add_new_samples_AL(sampled_data,
upd_dataCurLabels, upd_dataCurFeatsub, upd_dataCur$ID_unit,
new_trainFeatVSVM, new_trainLabelsVSVM,
newSize_for_iter,
clusterSizes[cS] ) # always greater than newSize_for_iter, # 60, 80, 100, 120
# Extract new datasets
upd_dataCurFeatsub <- result$features
upd_dataCurLabels <- result$labels
# get SV of labeled samples
upd_SVindex_ud = upd_dataCur$ID_unit %in% result$IDunit
new_trainFeat <- result$new_trainFeatVSVM
new_trainLabels <- result$new_trainLabelsVSVM
# **********************
# get original SVs of base SVM
SVindex_ud = tmp_new_tunedSVM$finalModel@SVindex
# SVindex_ud = 1:nrow(new_trainFeatVSVM)
new_trainFeatVSVM=new_trainFeatVSVM[SVindex_ud,]
new_trainLabelsVSVM=new_trainLabelsVSVM[SVindex_ud]
new_trainFeatVSVM <- rbind(new_trainFeatVSVM, setNames(new_trainFeat, names))
new_trainLabelsVSVM <- unlist(list(new_trainLabelsVSVM, new_trainLabels))
SVtotal = setNames(cbind(new_trainFeatVSVM, new_trainLabelsVSVM),c(objInfoNames[-length(objInfoNames)],"REF"))
# **********************
# REF_ud = predict(tmp_new_tunedSVM, new_trainFeat)
REF_ud = new_trainLabels
# confusionMatrix(new_trainLabels,predict(bestFittingModel, new_trainFeat))
SVtotal_ud = cbind(new_trainFeat, REF_ud)
if(invariance=="scale"){
if(city=="cologne"){
SVL_variables = list(
# list(SVtotal, SVL2 = trainDataCur[SVindex,c((sindexSVMDATA - 2*numFeat):(sindexSVMDATA - numFeat - 1), ncol(trainDataCur))]),
# list(SVtotal, SVL3 = trainDataCur[SVindex,c((sindexSVMDATA - numFeat):(sindexSVMDATA -1), ncol(trainDataCur))]),
# list(SVtotal, SVL5 = trainDataCur[SVindex,c((sindexSVMDATA + numFeat):((sindexSVMDATA + 2*numFeat)-1),ncol(trainDataCur))]),
# list(SVtotal, SVL6 = trainDataCur[SVindex,c((sindexSVMDATA + 2*numFeat):((sindexSVMDATA + 3*numFeat)-1),ncol(trainDataCur))]),
# list(SVtotal, SVL7 = trainDataCur[SVindex,c((sindexSVMDATA + 3*numFeat):((sindexSVMDATA + 4*numFeat)-1),ncol(trainDataCur))]),
# list(SVtotal, SVL8 = trainDataCur[SVindex,c((sindexSVMDATA + 4*numFeat):((sindexSVMDATA + 5*numFeat)-1),ncol(trainDataCur))]),
# list(SVtotal, SVL9 = trainDataCur[SVindex,c((sindexSVMDATA + 5*numFeat):((sindexSVMDATA + 6*numFeat)-1),ncol(trainDataCur))]),
# list(SVtotal, SVL10 = trainDataCur[SVindex,c((sindexSVMDATA + 6*numFeat):((sindexSVMDATA + 7*numFeat)-1),ncol(trainDataCur))]),
# list(SVtotal, SVL11 = trainDataCur[SVindex,c((sindexSVMDATA + 7*numFeat):((sindexSVMDATA + 8*numFeat)-1),ncol(trainDataCur))]),
list(SVtotal_ud, SVL2=cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA - 2*numFeat):(sindexSVMDATA - numFeat - 1))],REF_ud)),
list(SVtotal_ud, SVL3=cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA - numFeat):(sindexSVMDATA -1))],REF_ud)),
list(SVtotal_ud, SVL5=cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + numFeat):((sindexSVMDATA + 2*numFeat)-1))],REF_ud)),
list(SVtotal_ud, SVL6=cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + 2*numFeat):((sindexSVMDATA + 3*numFeat)-1))],REF_ud)),
list(SVtotal_ud, SVL7=cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + 3*numFeat):((sindexSVMDATA + 4*numFeat)-1))],REF_ud)),
list(SVtotal_ud, SVL8=cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + 4*numFeat):((sindexSVMDATA + 5*numFeat)-1))],REF_ud)),
list(SVtotal_ud, SVL9=cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + 5*numFeat):((sindexSVMDATA + 6*numFeat)-1))],REF_ud)),
list(SVtotal_ud, SVL10=cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + 6*numFeat):((sindexSVMDATA + 7*numFeat)-1))],REF_ud)),
list(SVtotal_ud, SVL11=cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + 7*numFeat):((sindexSVMDATA + 8*numFeat)-1))],REF_ud))
)
}else{
SVL_variables = list(
# list(SVtotal, SVL2 = trainDataCur[SVindex,c((sindexSVMDATA - 2*numFeat):(sindexSVMDATA - numFeat - 1), ncol(trainDataCur))]),
# list(SVtotal, SVL3 = trainDataCur[SVindex,c((sindexSVMDATA - numFeat):(sindexSVMDATA -1), ncol(trainDataCur))]),
# list(SVtotal, SVL5 = trainDataCur[SVindex,c((sindexSVMDATA + numFeat):((sindexSVMDATA + 2*numFeat)-1),ncol(trainDataCur))]),
# list(SVtotal, SVL6 = trainDataCur[SVindex,c((sindexSVMDATA + 2*numFeat):((sindexSVMDATA + 3*numFeat)-1),ncol(trainDataCur))]),
# list(SVtotal, SVL7 = trainDataCur[SVindex,c((sindexSVMDATA + 3*numFeat):((sindexSVMDATA + 4*numFeat)-1),ncol(trainDataCur))]),
# list(SVtotal, SVL8 = trainDataCur[SVindex,c((sindexSVMDATA + 4*numFeat):((sindexSVMDATA + 5*numFeat)-1),ncol(trainDataCur))]),
# list(SVtotal, SVL9 = trainDataCur[SVindex,c((sindexSVMDATA + 5*numFeat):((sindexSVMDATA + 6*numFeat)-1),ncol(trainDataCur))]),
list(SVtotal_ud, SVL2=(cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA - 2*numFeat):(sindexSVMDATA - numFeat - 1))],REF_ud))),
list(SVtotal_ud, SVL3=(cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA - numFeat):(sindexSVMDATA -1))],REF_ud))),
list(SVtotal_ud, SVL5=(cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + numFeat):((sindexSVMDATA + 2*numFeat)-1))],REF_ud))),
list(SVtotal_ud, SVL6=(cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + 2*numFeat):((sindexSVMDATA + 3*numFeat)-1))],REF_ud))),
list(SVtotal_ud, SVL7=(cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + 3*numFeat):((sindexSVMDATA + 4*numFeat)-1))],REF_ud))),
list(SVtotal_ud, SVL8=(cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + 4*numFeat):((sindexSVMDATA + 5*numFeat)-1))],REF_ud))),
list(SVtotal_ud, SVL9=(cbind(upd_dataCur[upd_SVindex_ud,c((sindexSVMDATA + 5*numFeat):((sindexSVMDATA + 6*numFeat)-1))],REF_ud)))
)
}
}else{
SVL_variables = list(
# list(SVtotal, trainDataCur[SVindex,c((numFeat+1):(2*numFeat),ncol(trainDataCur))]),
# list(SVtotal, trainDataCur[SVindex,c(((2*numFeat)+1):(3*numFeat),ncol(trainDataCur))]),
# list(SVtotal, trainDataCur[SVindex,c(((3*numFeat)+1):(4*numFeat),ncol(trainDataCur))]),
# list(SVtotal, trainDataCur[SVindex,c(((4*numFeat)+1):(5*numFeat),ncol(trainDataCur))]),
# list(SVtotal, trainDataCur[SVindex,c(((5*numFeat)+1):(6*numFeat),ncol(trainDataCur))]),
# list(SVtotal, trainDataCur[SVindex,c(((6*numFeat)+1):(7*numFeat),ncol(trainDataCur))]),
# list(SVtotal, trainDataCur[SVindex,c(((7*numFeat)+1):(8*numFeat),ncol(trainDataCur))]),
# list(SVtotal, trainDataCur[SVindex,c(((8*numFeat)+1):(9*numFeat),ncol(trainDataCur))]),
list(SVtotal_ud, S01C09=(cbind(upd_dataCur[upd_SVindex_ud,c((numFeat+1):(2*numFeat))],REF_ud))),
list(SVtotal_ud, S03C05=(cbind(upd_dataCur[upd_SVindex_ud,c(((2*numFeat)+1):(3*numFeat))],REF_ud))),
list(SVtotal_ud, S03C07=(cbind(upd_dataCur[upd_SVindex_ud,c(((3*numFeat)+1):(4*numFeat))],REF_ud))),
list(SVtotal_ud, S05C03=(cbind(upd_dataCur[upd_SVindex_ud,c(((4*numFeat)+1):(5*numFeat))],REF_ud))),
list(SVtotal_ud, S05C05=(cbind(upd_dataCur[upd_SVindex_ud,c(((5*numFeat)+1):(6*numFeat))],REF_ud))),
list(SVtotal_ud, S05C07=(cbind(upd_dataCur[upd_SVindex_ud,c(((6*numFeat)+1):(7*numFeat))],REF_ud))),
list(SVtotal_ud, S07C03=(cbind(upd_dataCur[upd_SVindex_ud,c(((7*numFeat)+1):(8*numFeat))],REF_ud))),
list(SVtotal_ud, S09C01=(cbind(upd_dataCur[upd_SVindex_ud,c(((8*numFeat)+1):(9*numFeat))],REF_ud)))
)
} #
upd_SLresult <- self_learn(testFeatsub, testLabels, bound = c(0.05, 0.1, 0.3), boundMargin = c(0.5, 0.3, 0.2), model_name_AL_VSVMSL, SVtotal, objInfoNames,rem_extrem,rem_extrem_kerneldist, #classProb=TRUE,
SVL_variables, tmp_new_tunedSVM$finalModel)
tmp_new_tunedSVM <- upd_SLresult$bestFittingModel
new_trainFeatVSVM <- upd_SLresult$best_trainFeatVSVM
new_trainLabelsVSVM <- as.character(upd_SLresult$best_trainLabelsVSVM)
# length(best_trainLabelsVSVM)
# length(bestFittingModel$finalModel@SVindex)
# length(new_trainLabels)
# length(new_trainLabelsVSVM)
# new_trainFeatVSVM <- rbind(new_trainFeatVSVM, setNames(new_trainFeat, names))
# new_trainLabelsVSVM <- unlist(list(new_trainLabelsVSVM, new_trainLabels))
# # Get list with index of trainData to split between train and test in svmFit
# countTrainDataUn = nrow(new_trainFeatVSVM)
# indexTrainDataUn_it = list(c(1:countTrainDataUn))
# # Join of train and test data (seperable in svmFit through indexes)
# tuneFeatVSVMUn_it = rbind(new_trainFeatVSVM, setNames(testFeatsub, names))
# tuneLabelsVSVMUn_it = unlist(list(new_trainLabelsVSVM, testLabels))
# tmp_new_tunedSVM = svmFit(tuneFeatVSVMUn_it, tuneLabelsVSVMUn_it, indexTrainDataUn_it, showPrg = FALSE)
upd_dataCur <- upd_dataCur[-c(result$IDunit), ]
}
t.time <- round(as.numeric((Sys.time() - trainStart.time), units = "secs"), 3)
tmp_pred = predict(tmp_new_tunedSVM, validateFeatsub)
tmp_acc  = confusionMatrix(tmp_pred, validateLabels)
# if(actAcc < tmp_new_tunedSVM$resample$Kappa){ print(paste0("current best kappa: ",round(tmp_new_tunedSVM$resample$Kappa,4)))
if(actAcc < tmp_acc$overall["Accuracy"]){ print(paste0("current best accuracy: ",round(tmp_acc$overall["Accuracy"],5)," | related kappa: ",round(tmp_new_tunedSVM$resample$Kappa,4)))
new_tunedSVM = tmp_new_tunedSVM
actAcc = tmp_acc$overall["Accuracy"] # tmp_new_tunedSVM$resample$Kappa #
best_resample = resampledSize[rS]
best_newSize4iter = newSizes[nS4it]
best_classSize = classSize[clS]
best_cluster = clusterSizes[cS]
train.time = t.time
}
}
}
}
}
fin_predLabelsVSVM_SL_itAL = predict(new_tunedSVM, validateFeatsub)
accVSVM_SL_itAL  = confusionMatrix(fin_predLabelsVSVM_SL_itAL, validateLabels)
print(paste0("VSVM_SL - AL accuracy: ",round(accVSVM_SL_itAL$overall["Accuracy"],5)," | training time: ",train.time,"sec"))
if(actAcc>best_acc){
best_acc <- actAcc
best_model <- model_name_AL_VSVMSL
}
gc()
AccuracyVSVM_SL_Un_it[realization,sample_size] = as.numeric(accVSVM_SL_itAL$overall["Accuracy"])
# AccuracyVSVM_SL_Un_b_ud[realization,sample_size] = as.numeric(accVSVM_SL_Un_b_ud$overall["Accuracy"])
# AccuracyVSVM_SL_Un_b_ms[realization,sample_size] = as.numeric(accVSVM_SL_Un_b_ms$overall["Accuracy"])
# AccuracyVSVM_SL_Un_b_mclu[realization,sample_size] = as.numeric(accVSVM_SL_Un_b_mclu$overall["Accuracy"])
# AccuracyVSVM_SL_Un_b_mclp[realization,sample_size] = as.numeric(accVSVM_SL_Un_b_mclp$overall["Accuracy"])
KappaVSVM_SL_Un_it[realization,sample_size] = as.numeric(accVSVM_SL_itAL$overall["Kappa"])
# KappaVSVM_SL_Un_b_ud[realization,sample_size] = as.numeric(accVSVM_SL_Un_b_ud$overall["Kappa"])
# KappaVSVM_SL_Un_b_ms[realization,sample_size] = as.numeric(accVSVM_SL_Un_b_ms$overall["Kappa"])
# KappaVSVM_SL_Un_b_mclu[realization,sample_size] = as.numeric(accVSVM_SL_Un_b_mclu$overall["Kappa"])
# KappaVSVM_SL_Un_b_mclp[realization,sample_size] = as.numeric(accVSVM_SL_Un_b_mclp$overall["Kappa"])
}
resampledSize
newSizes
clusterSizes
